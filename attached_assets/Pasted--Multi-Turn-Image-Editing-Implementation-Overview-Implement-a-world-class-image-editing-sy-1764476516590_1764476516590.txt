# Multi-Turn Image Editing Implementation

## Overview

Implement a world-class image editing system using Gemini 3 Pro Image with thought signature preservation. This allows users to make iterative edits to generated images WITHOUT regenerating from scratch - the AI "remembers" what it created and applies targeted modifications.

---

## Phase 1: Database Schema Updates

### Task 1.1: Add columns to generations table

Add these columns to your existing `generations` table:

```sql
ALTER TABLE generations ADD COLUMN conversation_history JSONB;
ALTER TABLE generations ADD COLUMN parent_generation_id TEXT REFERENCES generations(id);
ALTER TABLE generations ADD COLUMN edit_prompt TEXT;
```

**Column purposes:**
- `conversation_history`: Stores the full Gemini API response including thought signatures (CRITICAL for multi-turn editing)
- `parent_generation_id`: Links to the original generation if this is an edit
- `edit_prompt`: The edit instruction used (for display in UI)

---

## Phase 2: Backend - Modify Generate Endpoint

### Task 2.1: Update your existing generate/transform endpoint

Find your current image generation endpoint (likely `/api/transform` or `/api/generate`) and modify it to store the conversation history.

**Before (current):**
```javascript
// You probably have something like this
const response = await genai.models.generateContent({
  model: "gemini-3-pro-image-preview",
  contents: contents,
  config: { responseModalities: ["TEXT", "IMAGE"], ... }
});

// Extract image and save
const imagePart = response.candidates[0].content.parts.find(p => p.inlineData);
// ... save to disk
// ... create generation record
```

**After (updated):**
```javascript
// Build the user message parts
const userParts = [];

// Add reference images if any
if (referenceImages && referenceImages.length > 0) {
  for (const img of referenceImages) {
    userParts.push({
      inlineData: {
        mimeType: img.mimeType || "image/png",
        data: img.base64
      }
    });
  }
}

// Add the text prompt
userParts.push({ text: prompt });

// Build the contents array for the API call
const contents = [
  { role: "user", parts: userParts }
];

// Call Gemini API
const response = await genai.models.generateContent({
  model: "gemini-3-pro-image-preview",
  contents: contents,
  config: {
    responseModalities: ["TEXT", "IMAGE"],
    // ... your other config like resolution, aspectRatio, etc.
  }
});

// Extract image from response
const modelResponse = response.candidates[0].content;
const imagePart = modelResponse.parts.find(p => p.inlineData);

if (!imagePart) {
  throw new Error("No image in response");
}

// Save image to disk
const imageBuffer = Buffer.from(imagePart.inlineData.data, 'base64');
const fileName = `generation_${Date.now()}.png`;
const imagePath = path.join(uploadsDir, fileName);
await fs.writeFile(imagePath, imageBuffer);

// CRITICAL: Build and store conversation history for future edits
// This includes the thought signatures that Gemini needs to "remember" the image
const conversationHistory = [
  { role: "user", parts: userParts },
  modelResponse  // This contains thoughtSignature fields - DO NOT MODIFY
];

// Create generation record in database
const generation = await db.insert(generations).values({
  id: generateId(),
  prompt: prompt,
  generatedImagePath: imagePath,
  conversationHistory: JSON.stringify(conversationHistory),  // Store as JSON
  parentGenerationId: null,  // This is an original, not an edit
  editPrompt: null,
  createdAt: new Date(),
  // ... your other fields
}).returning();

return {
  success: true,
  generationId: generation.id,
  imageUrl: `/uploads/${fileName}`,
  canEdit: true
};
```

---

## Phase 3: Backend - Create Edit Endpoint

### Task 3.1: Create POST `/api/generations/:id/edit` endpoint

Create a new endpoint that handles image editing using the stored conversation history.

```javascript
app.post('/api/generations/:id/edit', async (req, res) => {
  try {
    const { id } = req.params;
    const { editPrompt } = req.body;

    // Validate input
    if (!editPrompt || editPrompt.trim().length === 0) {
      return res.status(400).json({ 
        success: false, 
        error: "Edit prompt is required" 
      });
    }

    // Load the parent generation
    const parentGeneration = await db.query.generations.findFirst({
      where: eq(generations.id, id)
    });

    if (!parentGeneration) {
      return res.status(404).json({ 
        success: false, 
        error: "Generation not found" 
      });
    }

    // Check if this generation supports editing
    if (!parentGeneration.conversationHistory) {
      return res.status(400).json({ 
        success: false, 
        error: "This generation does not support editing. It was created before the edit feature was available." 
      });
    }

    // Parse the stored conversation history
    let history;
    try {
      history = JSON.parse(parentGeneration.conversationHistory);
    } catch (e) {
      return res.status(500).json({ 
        success: false, 
        error: "Failed to parse conversation history" 
      });
    }

    // Append the new edit request to the history
    // This is the key to multi-turn editing - we send the FULL history
    history.push({
      role: "user",
      parts: [{ text: editPrompt }]
    });

    // Call Gemini with the full conversation history
    // The thought signatures in the history allow Gemini to "remember" the image
    const response = await genai.models.generateContent({
      model: "gemini-3-pro-image-preview",
      contents: history,
      config: {
        responseModalities: ["TEXT", "IMAGE"],
        // Use same settings as original or allow customization
      }
    });

    // Extract the new image
    const modelResponse = response.candidates[0].content;
    const imagePart = modelResponse.parts.find(p => p.inlineData);

    if (!imagePart) {
      return res.status(500).json({ 
        success: false, 
        error: "Gemini did not return an image. Try a different edit prompt." 
      });
    }

    // Save the new image
    const imageBuffer = Buffer.from(imagePart.inlineData.data, 'base64');
    const fileName = `generation_${Date.now()}.png`;
    const imagePath = path.join(uploadsDir, fileName);
    await fs.writeFile(imagePath, imageBuffer);

    // Update history with the new response (for potential future edits)
    history.push(modelResponse);

    // Create a NEW generation record (don't overwrite the original)
    const newGeneration = await db.insert(generations).values({
      id: generateId(),
      prompt: parentGeneration.prompt,  // Keep original prompt for reference
      editPrompt: editPrompt,           // Store the edit instruction
      generatedImagePath: imagePath,
      conversationHistory: JSON.stringify(history),
      parentGenerationId: parentGeneration.id,  // Link to parent
      createdAt: new Date(),
      // Copy relevant settings from parent
      aspectRatio: parentGeneration.aspectRatio,
      resolution: parentGeneration.resolution,
      // ... other fields as needed
    }).returning();

    return res.json({
      success: true,
      generationId: newGeneration.id,
      imageUrl: `/uploads/${fileName}`,
      parentId: parentGeneration.id,
      canEdit: true
    });

  } catch (error) {
    console.error('Edit error:', error);
    return res.status(500).json({ 
      success: false, 
      error: error.message || "Failed to edit image" 
    });
  }
});
```

### Task 3.2: Create GET `/api/generations/:id/history` endpoint (Optional but recommended)

This endpoint returns the edit chain for a generation.

```javascript
app.get('/api/generations/:id/history', async (req, res) => {
  try {
    const { id } = req.params;

    // Get the current generation
    const generation = await db.query.generations.findFirst({
      where: eq(generations.id, id)
    });

    if (!generation) {
      return res.status(404).json({ error: "Generation not found" });
    }

    // Build the history chain by following parent links
    const chain = [];
    let current = generation;

    while (current) {
      chain.unshift({
        id: current.id,
        imageUrl: `/uploads/${path.basename(current.generatedImagePath)}`,
        editPrompt: current.editPrompt,
        createdAt: current.createdAt,
        isOriginal: !current.parentGenerationId
      });

      if (current.parentGenerationId) {
        current = await db.query.generations.findFirst({
          where: eq(generations.id, current.parentGenerationId)
        });
      } else {
        current = null;
      }
    }

    return res.json({
      success: true,
      history: chain,
      totalEdits: chain.length - 1
    });

  } catch (error) {
    console.error('History error:', error);
    return res.status(500).json({ error: "Failed to fetch history" });
  }
});
```

---

## Phase 4: Frontend - Clean Up Old Re-Edit Code

### Task 4.1: Remove from Home.tsx

Find and remove all code related to the old re-edit functionality:

```javascript
// REMOVE: Any useEffect or code that checks localStorage for reEditGeneration
// Example of what to remove:
useEffect(() => {
  const reEditData = localStorage.getItem('reEditGeneration');
  if (reEditData) {
    // ... loading re-edit data
  }
}, []);

// REMOVE: Any state related to re-editing
const [reEditGeneration, setReEditGeneration] = useState(null);

// REMOVE: Any functions like handleReEdit or similar
const handleReEdit = () => { ... };
```

### Task 4.2: Remove from GenerationDetail.tsx

Remove the old Re-Edit button and handler:

```javascript
// REMOVE: The handleReEdit function
const handleReEdit = () => {
  localStorage.setItem('reEditGeneration', JSON.stringify(generation));
  navigate('/');
};

// REMOVE: The Re-Edit button from the UI
<Button onClick={handleReEdit}>
  <Edit className="w-4 h-4 mr-2" />
  Re-Edit
</Button>
```

---

## Phase 5: Frontend - Build New Edit UI

### Task 5.1: Update GenerationDetail.tsx with new Edit functionality

Replace the removed code with the new edit system:

```tsx
import { useState } from 'react';
import { useNavigate, Link } from 'react-router-dom';
import { Pencil, X, Loader2, History } from 'lucide-react';
import { Button } from '@/components/ui/button';
import { Textarea } from '@/components/ui/textarea';
import { useToast } from '@/hooks/use-toast';

// Quick edit presets for common modifications
const QUICK_EDITS = [
  { label: 'Warmer lighting', prompt: 'Make the lighting warmer and more golden' },
  { label: 'Cooler tones', prompt: 'Make the colors cooler with blue tones' },
  { label: 'Add shadows', prompt: 'Add more dramatic shadows for depth' },
  { label: 'Softer look', prompt: 'Make the image softer and more diffused' },
  { label: 'More contrast', prompt: 'Increase the contrast for a punchier look' },
  { label: 'Blur background', prompt: 'Blur the background to focus on the main subject' },
];

interface Generation {
  id: string;
  imageUrl: string;
  prompt: string;
  editPrompt?: string;
  parentGenerationId?: string;
  canEdit?: boolean;
}

interface GenerationDetailProps {
  generation: Generation;
}

export function GenerationDetail({ generation }: GenerationDetailProps) {
  const [isEditPanelOpen, setIsEditPanelOpen] = useState(false);
  const [editPrompt, setEditPrompt] = useState('');
  const [isLoading, setIsLoading] = useState(false);
  const navigate = useNavigate();
  const { toast } = useToast();

  const handleApplyEdit = async () => {
    if (!editPrompt.trim()) {
      toast({
        title: "Edit prompt required",
        description: "Please describe what you'd like to change",
        variant: "destructive"
      });
      return;
    }

    setIsLoading(true);

    try {
      const response = await fetch(`/api/generations/${generation.id}/edit`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ editPrompt: editPrompt.trim() })
      });

      const data = await response.json();

      if (!response.ok || !data.success) {
        throw new Error(data.error || 'Edit failed');
      }

      toast({
        title: "Edit applied!",
        description: "Navigating to your edited image..."
      });

      // Navigate to the new edited generation
      navigate(`/generation/${data.generationId}`);

    } catch (error) {
      console.error('Edit error:', error);
      toast({
        title: "Edit failed",
        description: error.message || "Something went wrong. Please try again.",
        variant: "destructive"
      });
    } finally {
      setIsLoading(false);
    }
  };

  const handleQuickEdit = (prompt: string) => {
    setEditPrompt(prompt);
  };

  const handleCloseEditPanel = () => {
    setIsEditPanelOpen(false);
    setEditPrompt('');
  };

  return (
    <div className="space-y-4">
      {/* Image Display */}
      <div className="relative rounded-lg overflow-hidden">
        <img 
          src={generation.imageUrl} 
          alt="Generated image"
          className="w-full h-auto"
        />
      </div>

      {/* Edit Lineage Info - Show if this is an edited version */}
      {generation.parentGenerationId && (
        <div className="flex items-center gap-2 text-sm text-muted-foreground bg-muted/50 px-3 py-2 rounded-lg">
          <History className="w-4 h-4" />
          <span>
            Edited from{' '}
            <Link 
              to={`/generation/${generation.parentGenerationId}`}
              className="text-primary hover:underline"
            >
              previous version
            </Link>
          </span>
          {generation.editPrompt && (
            <span className="text-xs">
              — "{generation.editPrompt}"
            </span>
          )}
        </div>
      )}

      {/* Action Buttons */}
      <div className="flex gap-2">
        <Button 
          onClick={() => setIsEditPanelOpen(true)}
          disabled={isEditPanelOpen || !generation.canEdit}
        >
          <Pencil className="w-4 h-4 mr-2" />
          Edit
        </Button>
        
        {/* Your other buttons like Download, Share, etc. */}
        <Button variant="outline">
          Download
        </Button>
      </div>

      {/* Cannot Edit Warning */}
      {!generation.canEdit && (
        <p className="text-sm text-muted-foreground">
          This image was generated before the edit feature was available.
        </p>
      )}

      {/* Edit Panel */}
      {isEditPanelOpen && (
        <div className="border rounded-lg p-4 bg-card space-y-4">
          {/* Header */}
          <div className="flex items-center justify-between">
            <h3 className="font-semibold">What would you like to change?</h3>
            <Button 
              variant="ghost" 
              size="icon"
              onClick={handleCloseEditPanel}
            >
              <X className="w-4 h-4" />
            </Button>
          </div>

          {/* Quick Edit Presets */}
          <div className="space-y-2">
            <p className="text-sm text-muted-foreground">Quick edits:</p>
            <div className="flex flex-wrap gap-2">
              {QUICK_EDITS.map((preset) => (
                <button
                  key={preset.label}
                  onClick={() => handleQuickEdit(preset.prompt)}
                  className={`
                    px-3 py-1.5 text-sm rounded-full border transition-colors
                    ${editPrompt === preset.prompt 
                      ? 'bg-primary text-primary-foreground border-primary' 
                      : 'bg-background hover:bg-muted border-border'
                    }
                  `}
                >
                  {preset.label}
                </button>
              ))}
            </div>
          </div>

          {/* Custom Edit Input */}
          <div className="space-y-2">
            <p className="text-sm text-muted-foreground">Or describe your edit:</p>
            <Textarea
              value={editPrompt}
              onChange={(e) => setEditPrompt(e.target.value)}
              placeholder="e.g., 'make the steel bars more prominent' or 'add a subtle reflection on the floor'"
              rows={3}
              className="resize-none"
            />
          </div>

          {/* Action Buttons */}
          <div className="flex gap-2">
            <Button 
              onClick={handleApplyEdit}
              disabled={!editPrompt.trim() || isLoading}
              className="flex-1"
            >
              {isLoading ? (
                <>
                  <Loader2 className="w-4 h-4 mr-2 animate-spin" />
                  Applying edit...
                </>
              ) : (
                'Apply Edit'
              )}
            </Button>
            <Button 
              variant="outline"
              onClick={handleCloseEditPanel}
              disabled={isLoading}
            >
              Cancel
            </Button>
          </div>

          {/* Help Text */}
          <p className="text-xs text-muted-foreground">
            Tip: Short, specific prompts work best. The AI remembers your image and will only change what you ask for.
          </p>
        </div>
      )}
    </div>
  );
}
```

---

## Phase 6: Update API Response to Include canEdit Flag

### Task 6.1: Modify GET `/api/generations/:id` endpoint

Update your existing generation detail endpoint to include the `canEdit` flag:

```javascript
app.get('/api/generations/:id', async (req, res) => {
  const { id } = req.params;
  
  const generation = await db.query.generations.findFirst({
    where: eq(generations.id, id)
  });

  if (!generation) {
    return res.status(404).json({ error: "Not found" });
  }

  return res.json({
    id: generation.id,
    prompt: generation.prompt,
    editPrompt: generation.editPrompt,
    imageUrl: `/uploads/${path.basename(generation.generatedImagePath)}`,
    parentGenerationId: generation.parentGenerationId,
    canEdit: !!generation.conversationHistory,  // Can edit if we have history
    createdAt: generation.createdAt,
    // ... other fields
  });
});
```

---

## Testing Checklist

After implementation, test these scenarios:

### Basic Flow
- [ ] Generate a new image
- [ ] Verify `conversationHistory` is stored in database (check with SQL query)
- [ ] Click Edit button - panel appears
- [ ] Enter custom edit prompt and apply
- [ ] Verify new generation is created with `parentGenerationId` set
- [ ] Verify "Edited from previous version" link appears and works

### Quick Edits
- [ ] Click a quick edit preset button
- [ ] Verify prompt text is filled in
- [ ] Apply the edit
- [ ] Verify the change is visible in the new image

### Edit Chain
- [ ] Generate image → Edit → Edit again
- [ ] Verify each edit creates a new generation
- [ ] Verify you can navigate back through the chain
- [ ] Verify conversation history grows with each edit

### Error Handling
- [ ] Try to edit a generation without conversation_history
- [ ] Verify appropriate error message is shown
- [ ] Try empty edit prompt
- [ ] Verify validation prevents submission

### Edge Cases
- [ ] Very long edit prompts (should work)
- [ ] Special characters in edit prompts
- [ ] Rapid consecutive edit attempts

---

## Summary of Files to Modify

| File | Changes |
|------|---------|
| Database/Schema | Add `conversation_history`, `parent_generation_id`, `edit_prompt` columns |
| Generate endpoint | Store full conversation history with response |
| New: Edit endpoint | POST `/api/generations/:id/edit` |
| New: History endpoint | GET `/api/generations/:id/history` (optional) |
| GET generation endpoint | Add `canEdit` flag to response |
| Home.tsx | Remove all reEditGeneration localStorage code |
| GenerationDetail.tsx | Remove old Re-Edit, add new Edit panel UI |

---

## Why This Approach Is Best

1. **Thought Signatures**: By storing and replaying the full conversation history, Gemini "remembers" the image it created and can make targeted edits without regenerating from scratch.

2. **Cost Efficient**: Edits are cheaper than full regenerations because the model doesn't start from zero.

3. **Better Quality**: Edits maintain consistency with the original image - same style, lighting, composition.

4. **Version History**: Each edit is a new record, so users can compare versions and go back.

5. **Chain Edits**: Users can make multiple sequential edits, each building on the last.